{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUNEF MUCD 2021/2022  \n",
    "## Machine Learning\n",
    "## Análisis de Siniestralidad de Automóviles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autores:\n",
    "- Andrés Mahía Morado\n",
    "- Antonio Tello Gómez\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Base y Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado construimos el modelo base que nos servirá como referencia para comprobar el desempeño del resto de modelos. Por otro lado, también vamos entrenar un modelo Naive Bayes otro modelo sencillo que también nos servirá como referencia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, \\\n",
    "                            silhouette_score, recall_score, precision_score, make_scorer, \\\n",
    "                            roc_auc_score, f1_score, precision_recall_curve\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, \\\n",
    "                            classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from sklearn.dummy import DummyClassifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aux_func import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pd.read_parquet(\"../data/xtrain.parquet\")\n",
    "ytrain = pd.read_parquet(\"../data/ytrain.parquet\")\n",
    "xtest = pd.read_parquet(\"../data/xtest.parquet\")\n",
    "ytest = pd.read_parquet(\"../data/ytest.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modelo base emplea un valor fijo o valores aleatorios (Normalmente en función de algún estadistico de la distribución de la variable objetivo) para realizar la predicción de los valores del test. \n",
    "En nuestro caso hemos empleado la opción 'stratified' que genera predicciones aleatorias respetando la distribución de la variable objetivo.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 395 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DummyClassifier(random_state=0, strategy='stratified')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "modelo_base = DummyClassifier(strategy='stratified', random_state=0)\n",
    "modelo_base.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/modelo_base.pickle', 'wb') as f:\n",
    "    pickle.dump(modelo_base, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para no tener que ejecutar, saltarse el fit y ejecutar a partir de aquí\n",
    "with open('../models/modelo_base.pickle', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score of the model: 0.49958685184478924\n",
      "Accuracy of the model: 0.9702494339127026\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    997197\n",
      "           1       0.01      0.01      0.01     15456\n",
      "\n",
      "    accuracy                           0.97   1012653\n",
      "   macro avg       0.50      0.50      0.50   1012653\n",
      "weighted avg       0.97      0.97      0.97   1012653\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[982308  14889]\n",
      " [ 15238    218]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred = modelo_base.predict(xtest)\n",
    "ypred_proba = modelo_base.predict_proba(xtest)\n",
    "evaluate_model(ytest,ypred,ypred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo muy significativo de nuestro modelo base es que obtenemos un accuracy, la métrica por excelencia para evaluar los modelos de ML, del 97.02%. Si predijéramos que todo nuestro test pertenece a la clase 0 (strategy='most_frequent') obtendríamos un accuracy aún mayor, del 98.47%. Sin embargo, no estaríamos acercándonos de ninguna manera a nuestro objetivo que es predecir el máximo posible de la clase 1 sin renunciar a acertar en la clase 0. Por tanto, el accuracy no será una métrica muy útil a la hora de evaluar nuestros modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Naive Bayes es un clasificador basado en la aplicación del teorema de Bayes con la hipótesis de independencia condicional entre variables predictoras. Hipótesis conocida como ingenua, _naive_.  \n",
    "En nuestro caso hemos estimado un Gaussian Naive Bayes en el que asumimos que probabilidad de las variables predictoras sigue una distribución normal.  \n",
    "Este es el modelo más sencillo que tiene en cuenta las variables predictoras por ello también será una referencia muy útil para comparar el resto de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes = naive_bayes.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/GNB.pickle', 'wb') as f:\n",
    "    pickle.dump(naive_bayes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para no tener que ejecutar, saltarse el fit y ejecutar a partir de aquí\n",
    "with open('../models/GNB.pickle', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = naive_bayes.predict(xtest)\n",
    "ypred_proba = naive_bayes.predict_proba(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score of the model: 0.7873892350291511\n",
      "Accuracy of the model: 0.8959248627121037\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94    997197\n",
      "           1       0.07      0.48      0.12     15456\n",
      "\n",
      "    accuracy                           0.90   1012653\n",
      "   macro avg       0.53      0.69      0.53   1012653\n",
      "weighted avg       0.98      0.90      0.93   1012653\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[899825  97372]\n",
      " [  8020   7436]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(ytest,ypred,ypred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste del umbral de predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.003422, G-Mean=0.718\n",
      "ROC-AUC score of the model: 0.7873892350291511\n",
      "Accuracy of the model: 0.732287367933537\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.73      0.84    997197\n",
      "           1       0.04      0.70      0.07     15456\n",
      "\n",
      "    accuracy                           0.73   1012653\n",
      "   macro avg       0.52      0.72      0.46   1012653\n",
      "weighted avg       0.98      0.73      0.83   1012653\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[730680 266517]\n",
      " [  4583  10873]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# keep probabilities for the positive outcome only\n",
    "yhat = ypred_proba[:, 1]\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, yhat)\n",
    "\n",
    "gmeans = np.sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix = np.argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "ypred_new_threshold = (ypred_proba[:,1]>thresholds[ix]).astype(int)\n",
    "evaluate_model(ytest,ypred_new_threshold,ypred_proba)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75234cef4d4b5401408a5d3b72f4265569f6601e8da7c73f173a51e561ebd976"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('core_models': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

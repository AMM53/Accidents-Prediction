{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUNEF MUCD 2021/2022  \n",
    "## Machine Learning\n",
    "## Análisis de Siniestralidad de Automóviles\n",
    "\n",
    "### Autores:\n",
    "- Andrés Mahía Morado\n",
    "- Antonio Tello Gómez\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-12-18 18:22:10 +01:00)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, \\\n",
    "                            silhouette_score, recall_score, precision_score, make_scorer, \\\n",
    "                            roc_auc_score, f1_score, precision_recall_curve\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, \\\n",
    "                            classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import pickle\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from imblearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from imblearn.over_sampling import SMOTE\n",
    "%load_ext autotime\n",
    "\n",
    "from aux_func import evaluate_model, cargar_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pd.read_parquet(\"../data/xtrain.parquet\")\n",
    "ytrain = pd.read_parquet(\"../data/ytrain.parquet\")['fatality']\n",
    "xtest = pd.read_parquet(\"../data/xtest.parquet\")\n",
    "ytest = pd.read_parquet(\"../data/ytest.parquet\")['fatality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos pipeline preprocesado\n",
    "preprocessor = cargar_modelo('../models/preprocessor.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos modelos surgen como una alternativa a los árboles de decisión, y el problema que tienen cuando se usan de manera individual. Al utilizar un árbol de decisión, los resultados no son consistentes, y pueden variar en función de cambios en la composición de los conjuntos de entrenamiento y validación.\n",
    "\n",
    "El Random Forest utiliza muchos árboles, y la decisión final sobre una predicción concreta se basa en un sistema de voto. Este sistema se puede modificar, para ponderar el peso de los votos de los árboles en función de, por ejemplo, su precisión o el ROC-AUC Score (Área debajo de la curva ROC)\n",
    "\n",
    "Cada árbol realiza su partición en conjunto de train y test, y se ejecuta. No hay ningún tipo de regla que influya en qué observaciones puede usar un algortimo, son independientes de las que haya utilizado otro arbol\n",
    "\n",
    "Procedemos a entrenar el modelo.\n",
    "\n",
    "![Highway](https://www.freecodecamp.org/news/content/images/2020/08/how-random-forest-classifier-work.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline(steps=[\n",
    "    ('preprocesador', preprocessor), \n",
    "    \n",
    "    ('clasificador', RandomForestClassifier(n_jobs=-1, random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocesador',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['vehicle_age',\n",
       "                                                   'passenger_age',\n",
       "                                                   'vehicles_involved',\n",
       "                                                   'year']),\n",
       "                                                 ('fcat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value=nan,\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='i...\n",
       "                                                   'passenger_type']),\n",
       "                                                 ('mcat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('target',\n",
       "                                                                   TargetEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['crash_type', 'crash_place',\n",
       "                                                   'crash_weather',\n",
       "                                                   'surface_state',\n",
       "                                                   'road_slope',\n",
       "                                                   'traffic_state',\n",
       "                                                   'vehicle_type',\n",
       "                                                   'passenger_safety'])])),\n",
       "                ('clasificador',\n",
       "                 RandomForestClassifier(n_jobs=-1, random_state=0))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/RandomForest.pickle', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para no tener que ejecutar, saltarse el fit y ejecutar a partir de aquí\n",
    "with open('../models/RandomForest.pickle', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos las predicciones sobre los datos de validación y evaluamos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score of the model: 0.8140237379943902\n",
      "Accuracy of the model: 0.9850499300081134\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    799946\n",
      "           1       0.61      0.03      0.06     12291\n",
      "\n",
      "    accuracy                           0.99    812237\n",
      "   macro avg       0.80      0.52      0.53    812237\n",
      "weighted avg       0.98      0.99      0.98    812237\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[799694    252]\n",
      " [ 11891    400]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred = clf.predict(xtest)\n",
    "ypred_proba = clf.predict_proba(xtest)\n",
    "evaluate_model(ytest,ypred,ypred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste del umbral de predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al observar cómo nuestro modelo obtiene un valor de recall muy bajo para la clase minoritaria, nos planteamos ajustar el umbral de predicción siguiendo el punto que obtiene la mayor G-mean o media geométrica entre las tasas de \"true positives\" y \"false positives\". La curva ROC nos permite determinar este punto, como observaremos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.016667, G-Mean=0.753\n",
      "ROC-AUC score of the model: 0.8140237379943902\n",
      "Accuracy of the model: 0.767305601690147\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.77      0.87    799946\n",
      "           1       0.05      0.74      0.09     12291\n",
      "\n",
      "    accuracy                           0.77    812237\n",
      "   macro avg       0.52      0.75      0.48    812237\n",
      "weighted avg       0.98      0.77      0.85    812237\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[614163 185783]\n",
      " [  3220   9071]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# keep probabilities for the positive outcome only\n",
    "yhat = ypred_proba[:, 1]\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, yhat)\n",
    "\n",
    "gmeans = np.sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix = np.argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "ypred_new_threshold = (ypred_proba[:,1]>thresholds[ix]).astype(int)\n",
    "evaluate_model(ytest,ypred_new_threshold,ypred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar como el ajuste del threshold dota al modelo de un mayor recall para los casos de la clase minoritaria, lo cual nos interesa desde un punto de vista práctico a pesar de reducir la precisión y accuracy del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobación de overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos si el modelo sufre de overfitting, realizando una predicción sobre la serie de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.214310, G-Mean=1.000\n",
      "ROC-AUC score of the model: 0.9999989972620618\n",
      "Accuracy of the model: 0.9997620766125619\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   3200049\n",
      "           1       0.98      1.00      0.99     48896\n",
      "\n",
      "    accuracy                           1.00   3248945\n",
      "   macro avg       0.99      1.00      1.00   3248945\n",
      "weighted avg       1.00      1.00      1.00   3248945\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[3199290     759]\n",
      " [     14   48882]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred = clf.predict(xtrain)\n",
    "ypred_proba = clf.predict_proba(xtrain)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "yhat = ypred_proba[:, 1]\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytrain, yhat)\n",
    "\n",
    "gmeans = np.sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix = np.argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "ypred_new_threshold = (ypred_proba[:,1]>thresholds[ix]).astype(int)\n",
    "evaluate_model(ytrain,ypred_new_threshold,ypred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En efecto, el model Random Forest ha realizado un ajuste bastante notable. Posteriormente profundizaremos en este asunto, pero podemos afirmar que el modelo no generaliza bien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random-Forest con SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los modelos Random Forest y XGBoost también hemos realizado una prueba con una versión de los datos en los que realizamos un Oversample de la clase minoritaria mediante el algoritmo SMOTE. Probaremos esta técnica en estos primeros dos modelos más complejos con el objetivo de ver si merece la pena. Si consideramos que los resultados son peores a los obtenidos con los datos sin Oversample, nos mantendremos en la senda de usar los datos sin Oversample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-12-18 18:24:18 +01:00)\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline(steps=[\n",
    "    ('preprocesador', preprocessor),\n",
    "    ('smote', SMOTE(sampling_strategy=0.4, n_jobs=-1)),\n",
    "    ('clasificador', RandomForestClassifier(n_jobs=-1, random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocesador',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['vehicle_age',\n",
       "                                                   'passenger_age',\n",
       "                                                   'vehicles_involved',\n",
       "                                                   'year']),\n",
       "                                                 ('fcat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value=nan,\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='i...\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('target',\n",
       "                                                                   TargetEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['crash_type', 'crash_place',\n",
       "                                                   'crash_weather',\n",
       "                                                   'surface_state',\n",
       "                                                   'road_slope',\n",
       "                                                   'traffic_state',\n",
       "                                                   'vehicle_type',\n",
       "                                                   'passenger_safety'])])),\n",
       "                ('smote', SMOTE(n_jobs=-1, sampling_strategy=0.4)),\n",
       "                ('clasificador',\n",
       "                 RandomForestClassifier(n_jobs=-1, random_state=0))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8min 31s (started: 2021-12-18 18:24:21 +01:00)\n"
     ]
    }
   ],
   "source": [
    "clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.78 s (started: 2021-12-18 18:32:53 +01:00)\n"
     ]
    }
   ],
   "source": [
    "with open('../models/RandomForest_smote.pickle', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.48 s (started: 2021-12-18 18:32:57 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Para no tener que ejecutar, saltarse el fit y ejecutar a partir de aquí\n",
    "with open('../models/RandomForest_smote.pickle', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score of the model: 0.8150212650032423\n",
      "Accuracy of the model: 0.9848948028715757\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    799946\n",
      "           1       0.51      0.05      0.08     12291\n",
      "\n",
      "    accuracy                           0.98    812237\n",
      "   macro avg       0.75      0.52      0.54    812237\n",
      "weighted avg       0.98      0.98      0.98    812237\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[799403    543]\n",
      " [ 11726    565]]\n",
      "\n",
      "time: 26.1 s (started: 2021-12-18 18:32:59 +01:00)\n"
     ]
    }
   ],
   "source": [
    "ypred = clf.predict(xtest)\n",
    "ypred_proba = clf.predict_proba(xtest)\n",
    "evaluate_model(ytest,ypred,ypred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo sin aplicar el ajuste de threshold no es lo suficientemente descriptivo como para poder compararlo con su versión análoga. Procedemos a realizar dicho ajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste del umbral de predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.021480, G-Mean=0.749\n",
      "ROC-AUC score of the model: 0.8150212650032423\n",
      "Accuracy of the model: 0.76501562967459\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.77      0.87    799946\n",
      "           1       0.05      0.73      0.09     12291\n",
      "\n",
      "    accuracy                           0.77    812237\n",
      "   macro avg       0.52      0.75      0.48    812237\n",
      "weighted avg       0.98      0.77      0.85    812237\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[612370 187576]\n",
      " [  3287   9004]]\n",
      "\n",
      "time: 1.45 s (started: 2021-12-18 18:33:26 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# keep probabilities for the positive outcome only\n",
    "yhat = ypred_proba[:, 1]\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, yhat)\n",
    "\n",
    "gmeans = np.sqrt(tpr * (1-fpr))\n",
    "ix = np.argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "ypred_new_threshold = (ypred_proba[:,1]>thresholds[ix]).astype(int)\n",
    "evaluate_model(ytest,ypred_new_threshold,ypred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras realizar el ajuste del modelo, podemos afirmar que en nuestro caso concreto y para el tratamiento de los datos que hemos realizado, no existe una razón por la que usar la versión Oversample de los datos.\n",
    "Obtenemos una ligera diferencia en los resultados, obteniendo menor recall para la clase minoritaria. Comprobaremos si ocurre lo mismo en el modelo XGBoost."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75234cef4d4b5401408a5d3b72f4265569f6601e8da7c73f173a51e561ebd976"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('core_models': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

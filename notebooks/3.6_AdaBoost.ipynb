{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUNEF MUCD 2021/2022  \n",
    "## Machine Learning\n",
    "## Análisis de Siniestralidad de Automóviles\n",
    "\n",
    "### Autores:\n",
    "- Andrés Mahía Morado\n",
    "- Antonio Tello Gómez\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 531 ms (started: 2021-12-18 19:17:23 +01:00)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, \\\n",
    "                            silhouette_score, recall_score, precision_score, make_scorer, \\\n",
    "                            roc_auc_score, f1_score, precision_recall_curve\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, \\\n",
    "                            classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autotime\n",
    "\n",
    "from aux_func import evaluate_model, cargar_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.69 s (started: 2021-12-18 19:17:24 +01:00)\n"
     ]
    }
   ],
   "source": [
    "xtrain = pd.read_parquet(\"../data/xtrain.parquet\")\n",
    "ytrain = pd.read_parquet(\"../data/ytrain.parquet\")['fatality']\n",
    "xtest = pd.read_parquet(\"../data/xtest.parquet\")\n",
    "ytest = pd.read_parquet(\"../data/ytest.parquet\")['fatality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 141 ms (started: 2021-12-18 19:18:07 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#Cargamos pipeline preprocesado\n",
    "preprocessor = cargar_modelo('../models/preprocessor.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADA Boost es un clasificador, cuyo algoritmo se basa en la predicción iterativa de \"bloques\" de datos que va ajustando. Tras la primera iteración en la que analiza los datos completos, repite el proceso con aquellas secciones de los datos en los que no ha obtenido un buen resultado. A cada uno de estos bloques les asigna un peso o weight y la combinación de todos estos componen el modelo.\n",
    "\n",
    "![Highway](https://programmerclick.com/images/649/93a1dcc89731b8e5fc4dd19b7967f169.png)\n",
    "\n",
    "![Highway](https://editor.analyticsvidhya.com/uploads/626591024px-Ensemble_Boosting.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-12-18 19:18:10 +01:00)\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline(steps=[\n",
    "    ('preprocesador', preprocessor),\n",
    "    ('clasificador', AdaBoostClassifier(n_estimators=100, random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocesador',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['vehicle_age',\n",
       "                                                   'passenger_age',\n",
       "                                                   'vehicles_involved',\n",
       "                                                   'year']),\n",
       "                                                 ('fcat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value=nan,\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='i...\n",
       "                                                   'passenger_type']),\n",
       "                                                 ('mcat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('target',\n",
       "                                                                   TargetEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['crash_type', 'crash_place',\n",
       "                                                   'crash_weather',\n",
       "                                                   'surface_state',\n",
       "                                                   'road_slope',\n",
       "                                                   'traffic_state',\n",
       "                                                   'vehicle_type',\n",
       "                                                   'passenger_safety'])])),\n",
       "                ('clasificador',\n",
       "                 AdaBoostClassifier(n_estimators=100, random_state=0))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11min 22s (started: 2021-12-18 19:18:14 +01:00)\n"
     ]
    }
   ],
   "source": [
    "clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2021-12-18 19:29:37 +01:00)\n"
     ]
    }
   ],
   "source": [
    "with open('../models/AdaBoost.pickle', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2021-12-18 19:29:37 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Para no tener que ejecutar, saltarse el fit y ejecutar a partir de aquí\n",
    "with open('../models/AdaBoost.pickle', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos las predicciones sobre los datos de validación y evaluamos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score of the model: 0.8252876879924893\n",
      "Accuracy of the model: 0.9848369379873115\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    799946\n",
      "           1       0.43      0.01      0.01     12291\n",
      "\n",
      "    accuracy                           0.98    812237\n",
      "   macro avg       0.71      0.50      0.50    812237\n",
      "weighted avg       0.98      0.98      0.98    812237\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[799841    105]\n",
      " [ 12211     80]]\n",
      "\n",
      "time: 38.5 s (started: 2021-12-18 19:29:37 +01:00)\n"
     ]
    }
   ],
   "source": [
    "ypred = clf.predict(xtest)\n",
    "ypred_proba = clf.predict_proba(xtest)\n",
    "evaluate_model(ytest,ypred,ypred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste del umbral de predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a ajustar el umbral de la predicción para obtener un mayor recall en la variable minoritaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.489326, G-Mean=0.743\n",
      "ROC-AUC score of the model: 0.8252876879924893\n",
      "Accuracy of the model: 0.7402199111835585\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.85    799946\n",
      "           1       0.04      0.75      0.08     12291\n",
      "\n",
      "    accuracy                           0.74    812237\n",
      "   macro avg       0.52      0.74      0.46    812237\n",
      "weighted avg       0.98      0.74      0.84    812237\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[592068 207878]\n",
      " [  3125   9166]]\n",
      "\n",
      "time: 1.58 s (started: 2021-12-18 19:30:16 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# keep probabilities for the positive outcome only\n",
    "yhat = ypred_proba[:, 1]\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, yhat)\n",
    "\n",
    "gmeans = np.sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix = np.argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "ypred_new_threshold = (ypred_proba[:,1]>thresholds[ix]).astype(int)\n",
    "evaluate_model(ytest,ypred_new_threshold,ypred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El efecto del ajuste del threshold sobre el modelo ha sido parecido al observado previamente en el resto de modelos. Los resultados obtenidos son ligeramente inferiores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobación de overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos si el modelo sufre de overfitting, realizando una predicción sobre la serie de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.489563, G-Mean=0.743\n",
      "ROC-AUC score of the model: 0.8266178973156888\n",
      "Accuracy of the model: 0.763296393136849\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.76      0.86   3200049\n",
      "           1       0.04      0.72      0.08     48896\n",
      "\n",
      "    accuracy                           0.76   3248945\n",
      "   macro avg       0.52      0.74      0.47   3248945\n",
      "weighted avg       0.98      0.76      0.85   3248945\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[2444531  755518]\n",
      " [  13519   35377]]\n",
      "\n",
      "time: 2min 56s (started: 2021-12-18 19:30:18 +01:00)\n"
     ]
    }
   ],
   "source": [
    "ypred = clf.predict(xtrain)\n",
    "ypred_proba = clf.predict_proba(xtrain)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "yhat = ypred_proba[:, 1]\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytrain, yhat)\n",
    "\n",
    "gmeans = np.sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix = np.argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "ypred_new_threshold = (ypred_proba[:,1]>thresholds[ix]).astype(int)\n",
    "evaluate_model(ytrain,ypred_new_threshold,ypred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo ADA Boost ha obtenido un recall del 75% y 74% para las clases negativa y positiva respectivamente."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75234cef4d4b5401408a5d3b72f4265569f6601e8da7c73f173a51e561ebd976"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('core_models': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
